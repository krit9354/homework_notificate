{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "46So0YR_-inP"
      },
      "outputs": [],
      "source": [
        "import numpy as np #create array\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBlPZum4-0Ay"
      },
      "source": [
        "# Create Q-Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RM2zebM_H8w"
      },
      "source": [
        "## Represent 0 - empty, 1 - O, 2 - X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sel25Ie8-3ID"
      },
      "outputs": [],
      "source": [
        "qTable = {}#creat table to store state and action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap9u15OqAQj4"
      },
      "outputs": [],
      "source": [
        "representStates = [0, 1, 2]# empty = 0, O = 1, x = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnsmAnn3AX1d"
      },
      "outputs": [],
      "source": [
        "def getHashValue(hash):#creat new state\n",
        "  if not hash in qTable:\n",
        "    qTable[hash] = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "  return qTable[hash]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZMumPq5EjcF"
      },
      "outputs": [],
      "source": [
        "def updateHash(hash, newValue):\n",
        "  qTable[hash] = newValue #input value of reward to table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CO4ISqTI0H2"
      },
      "outputs": [],
      "source": [
        "def getPossibilityActions(hash):#find empty block and return that\n",
        "  possibilityActions = []\n",
        "  for stringValue in hash:\n",
        "    value = int(stringValue) \n",
        "    if value != 0:\n",
        "      possibilityActions.append(0)\n",
        "    else:\n",
        "      possibilityActions.append(1)\n",
        "  return np.array(possibilityActions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9UlmjOBJ3bg"
      },
      "outputs": [],
      "source": [
        "def stateToHash(state):#change state to hash\n",
        "  hash = \"\"\n",
        "  for s in state:\n",
        "    hash += str(int(s))\n",
        "  return hash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orwxa2uNEw90"
      },
      "source": [
        "# Create Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ygtjvf2OEyA5"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (4266044864.py, line 20)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m\u001b[0m\n\u001b[1;33m    qValues = getHashValue(has an h)\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "class Agent:\n",
        "  def __init__(self, epsilon=0.3, lr=0.3, gamma=0.99, isPlay=False):\n",
        "    \"\"\"\n",
        "    epsilon = if random number < epsilon then do random action else use qtable\n",
        "    lr = ?\n",
        "    gamma = ?\n",
        "    isPlay = ?\n",
        "    \"\"\"\n",
        "    self.epsilon = epsilon\n",
        "    self.lr = lr\n",
        "    self.gamma = gamma\n",
        "    self.isPlay = isPlay\n",
        "\n",
        "  def act(self, state):\n",
        "    rand = random.uniform(0, 1)#random number to use with epsilon\n",
        "    # convert state to hash\n",
        "    hash = stateToHash(state)\n",
        "\n",
        "    # get possibility actions\n",
        "    possibilityActions = getPossibilityActions(hash)#get list of empty block\n",
        "\n",
        "    # get Q value\n",
        "    qValues = getHashValue(hash)\n",
        "\n",
        "    # random Q value\n",
        "    if rand < self.epsilon and not self.isPlay:\n",
        "      qValues = np.random.rand(9)\n",
        "    \n",
        "    # avoid choice same action when qValue is negative\n",
        "    qValues = np.array(qValues)\n",
        "    if qValues.min() < 0:\n",
        "      base = abs(qValues.min())\n",
        "      qValues += base * 2\n",
        "\n",
        "    # dot product\n",
        "    qValues = np.multiply(qValues, possibilityActions)\n",
        "\n",
        "    # avoid use first action when nothing to choose\n",
        "    if qValues.sum() == 0:\n",
        "      qValues = possibilityActions\n",
        "\n",
        "    # random if have multiple best action\n",
        "    if np.count_nonzero(qValues == qValues.max()) > 1:\n",
        "      bestActions = [i for i in range(len(qValues)) if qValues[i] == qValues.max()]\n",
        "      return random.choice(bestActions)\n",
        "\n",
        "    # print(qValues)\n",
        "    # choose best action\n",
        "    return np.argmax(qValues)\n",
        "\n",
        "  def learn(self, state, nextState, action, reward, isDone):\n",
        "    hashState = stateToHash(state)\n",
        "    hashNextState = stateToHash(nextState)\n",
        "\n",
        "    qState = getHashValue(hashState)\n",
        "    qNextState = getHashValue(hashNextState)\n",
        "\n",
        "    possibilityActions = getPossibilityActions(hashNextState)\n",
        "    qNextState = np.multiply(qNextState, possibilityActions)\n",
        "\n",
        "    tmpQNextState = np.array(qNextState, copy=True)\n",
        "    if qNextState.min() < 0:\n",
        "      base = abs(qNextState.min())\n",
        "      tmpQNextState += base * 2\n",
        "\n",
        "    qState[action] += self.lr * (reward + self.gamma * qNextState[np.argmax(tmpQNextState)] - qState[action])\n",
        "    if isDone:\n",
        "      qState[action] = reward\n",
        "\n",
        "    updateHash(hashState, qState)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B04ggWUtMqq0"
      },
      "source": [
        "# Create Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp-l8dl3MnvB"
      },
      "outputs": [],
      "source": [
        "class Env:\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.board = np.zeros((9,))\n",
        "    self.isXTurn = True\n",
        "    return self.getState()\n",
        "\n",
        "  def checkRows(self, board):\n",
        "    for row in board:\n",
        "        if len(set(row)) == 1:\n",
        "            return row[0]\n",
        "    return 0\n",
        "\n",
        "  def checkDiagonals(self, board):\n",
        "    if len(set([board[i][i] for i in range(len(board))])) == 1:\n",
        "        return board[0][0]\n",
        "    if len(set([board[i][len(board)-i-1] for i in range(len(board))])) == 1:\n",
        "        return board[0][len(board)-1]\n",
        "    return 0\n",
        "\n",
        "  def checkWin(self):\n",
        "    board = self.board.reshape((3,3))\n",
        "    for newBoard in [board, np.transpose(board)]:\n",
        "        result = self.checkRows(newBoard)\n",
        "        if result:\n",
        "            return result\n",
        "    return self.checkDiagonals(board)\n",
        "\n",
        "  def checkDraw(self):\n",
        "    return self.checkWin() == 0\n",
        "\n",
        "  def checkDone(self):\n",
        "    return self.board.min() != 0 or self.checkWin() != 0\n",
        "\n",
        "  def getState(self):\n",
        "    return np.array(self.board, copy=True)\n",
        "\n",
        "  def showBoard(self):\n",
        "    prettyBoard = self.board.reshape((3, 3))\n",
        "    for row in prettyBoard:\n",
        "      print(\"|\", end='')\n",
        "      for col in row:\n",
        "        symbol = \"*\"\n",
        "        if col == 1:\n",
        "          symbol = \"X\"\n",
        "        elif col == 2:\n",
        "          symbol = \"O\"\n",
        "        print(symbol, end='')\n",
        "        print(\"|\", end='')\n",
        "      print(\"\")\n",
        "\n",
        "  def act(self, action):\n",
        "    reward = 0\n",
        "    player = 2\n",
        "    if self.isXTurn:\n",
        "      player = 1\n",
        "\n",
        "    self.board[action] = player\n",
        "    self.isXTurn = not self.isXTurn\n",
        "\n",
        "    winner = self.checkWin()\n",
        "    isDraw = self.checkDraw()\n",
        "    isDone = self.checkDone()\n",
        "\n",
        "    if winner:\n",
        "      reward = 1\n",
        "    \n",
        "    if isDraw:\n",
        "      reward = 0.5\n",
        "\n",
        "    nextState = np.array(self.board, copy=True)\n",
        "    return nextState, reward, isDone, {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykOq_6xOSY78"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeAqmo7eOPND"
      },
      "outputs": [],
      "source": [
        "env = Env()\n",
        "agent = Agent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kheBrWMVQYr4",
        "outputId": "e00b8121-bda3-4d5c-9642-9c35bceaf978"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.getState()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UkpQQoDTj5d"
      },
      "outputs": [],
      "source": [
        "episodes = 50000\n",
        "winner_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHVvgO8jU15t"
      },
      "outputs": [],
      "source": [
        "def swapSide(state):\n",
        "  newState = np.array(state, copy=True)\n",
        "\n",
        "  for i in range(len(newState)):\n",
        "    if newState[i] == 1:\n",
        "      newState[i] = 2\n",
        "    elif newState[i] == 2:\n",
        "      newState[i] = 1\n",
        "\n",
        "  return newState"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqWZTqQR9XBo"
      },
      "outputs": [],
      "source": [
        "def rotage(state, n = 1):\n",
        "  return np.rot90(state.reshape((3,3)), n).reshape((9,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb5LaUbXhs-k"
      },
      "outputs": [],
      "source": [
        "def rotageAction(action, n = 1):\n",
        "  board = np.zeros((9,))\n",
        "  board[action] = 1\n",
        "  board = rotage(board, n)\n",
        "  return np.argmax(board)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCb44IR3T5AU",
        "outputId": "a5949ef9-d3b7-40ec-833b-c9060c7d475d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode: 0\n",
            "episode: 1000\n",
            "episode: 2000\n",
            "episode: 3000\n",
            "episode: 4000\n",
            "episode: 5000\n",
            "episode: 6000\n",
            "episode: 7000\n",
            "episode: 8000\n",
            "episode: 9000\n",
            "episode: 10000\n",
            "episode: 11000\n",
            "episode: 12000\n",
            "episode: 13000\n",
            "episode: 14000\n",
            "episode: 15000\n",
            "episode: 16000\n",
            "episode: 17000\n",
            "episode: 18000\n",
            "episode: 19000\n",
            "episode: 20000\n",
            "episode: 21000\n",
            "episode: 22000\n",
            "episode: 23000\n",
            "episode: 24000\n",
            "episode: 25000\n",
            "episode: 26000\n",
            "episode: 27000\n",
            "episode: 28000\n",
            "episode: 29000\n",
            "episode: 30000\n",
            "episode: 31000\n",
            "episode: 32000\n",
            "episode: 33000\n",
            "episode: 34000\n",
            "episode: 35000\n",
            "episode: 36000\n",
            "episode: 37000\n",
            "episode: 38000\n",
            "episode: 39000\n",
            "episode: 40000\n",
            "episode: 41000\n",
            "episode: 42000\n",
            "episode: 43000\n",
            "episode: 44000\n",
            "episode: 45000\n",
            "episode: 46000\n",
            "episode: 47000\n",
            "episode: 48000\n",
            "episode: 49000\n"
          ]
        }
      ],
      "source": [
        "for episode in range(episodes):\n",
        "  isDone = False\n",
        "  state = env.reset()\n",
        "  prevState = state\n",
        "  prevAction = -1\n",
        "  isShouldLearn = False\n",
        "  \n",
        "  if episode % 1000 == 0:\n",
        "    print(\"episode:\", episode)\n",
        "\n",
        "  while not isDone:\n",
        "    state = env.getState()\n",
        "\n",
        "    if not env.isXTurn:\n",
        "      state = swapSide(state)\n",
        "    \n",
        "    action = agent.act(state)\n",
        "    nextState, reward, isDone, _ = env.act(action)\n",
        "    # env.showBoard()\n",
        "\n",
        "    # if X turn mean before act is not X turn\n",
        "    if env.isXTurn:\n",
        "      nextState = swapSide(nextState)\n",
        "\n",
        "    if isShouldLearn:\n",
        "      if isDone and not env.checkDraw():\n",
        "        prevReward = -1\n",
        "      elif isDone and env.checkDraw():\n",
        "        prevReward = 0.5\n",
        "      agent.learn(prevState, swapSide(nextState), prevAction, prevReward, isDone)\n",
        "      agent.learn(rotage(prevState, 1), rotage(swapSide(nextState), 1), rotageAction(prevAction, 1), prevReward, isDone)\n",
        "      agent.learn(rotage(prevState, 2), rotage(swapSide(nextState), 2), rotageAction(prevAction, 2), prevReward, isDone)\n",
        "      agent.learn(rotage(prevState, 3), rotage(swapSide(nextState), 3), rotageAction(prevAction, 3), prevReward, isDone)\n",
        "      \n",
        "\n",
        "    if isDone:\n",
        "      agent.learn(state, nextState, action, reward, isDone)\n",
        "      agent.learn(rotage(state, 1), rotage(nextState, 1), rotageAction(action, 1), reward, isDone)\n",
        "      agent.learn(rotage(state, 2), rotage(nextState, 2), rotageAction(action, 2), reward, isDone)\n",
        "      agent.learn(rotage(state, 3), rotage(nextState, 3), rotageAction(action, 3), reward, isDone)\n",
        "\n",
        "    prevState = state\n",
        "    prevAction = action\n",
        "    prevReward = reward\n",
        "    isShouldLearn = True\n",
        "\n",
        "  winner_history.append(env.checkWin())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR4PrfgRwhuS"
      },
      "outputs": [],
      "source": [
        "# qTable['000000000']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2AblgRDYOdE",
        "outputId": "77f8812b-8e90-4406-c102-e76993eda522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6477"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(qTable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLD5vEFnY_RS"
      },
      "outputs": [],
      "source": [
        "class TigTagToeGame:\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.board = np.zeros((9,))\n",
        "    self.isXTurn = True\n",
        "    return self.getState()\n",
        "\n",
        "  def checkRows(self, board):\n",
        "    for row in board:\n",
        "        if len(set(row)) == 1:\n",
        "            return row[0]\n",
        "    return 0\n",
        "\n",
        "  def checkDiagonals(self, board):\n",
        "    if len(set([board[i][i] for i in range(len(board))])) == 1:\n",
        "        return board[0][0]\n",
        "    if len(set([board[i][len(board)-i-1] for i in range(len(board))])) == 1:\n",
        "        return board[0][len(board)-1]\n",
        "    return 0\n",
        "\n",
        "  def checkWin(self):\n",
        "    board = self.board.reshape((3,3))\n",
        "    for newBoard in [board, np.transpose(board)]:\n",
        "        result = self.checkRows(newBoard)\n",
        "        if result:\n",
        "            return result\n",
        "    return self.checkDiagonals(board)\n",
        "\n",
        "  def checkDraw(self):\n",
        "    return self.checkWin() == 0\n",
        "\n",
        "  def checkDone(self):\n",
        "    return self.board.min() != 0 or self.checkWin() != 0\n",
        "\n",
        "  def getState(self):\n",
        "    return np.array(self.board, copy=True)\n",
        "\n",
        "  def showBoard(self):\n",
        "    prettyBoard = self.board.reshape((3, 3))\n",
        "    for row in prettyBoard:\n",
        "      print(\"|\", end='')\n",
        "      for col in row:\n",
        "        symbol = \"*\"\n",
        "        if col == 1:\n",
        "          symbol = \"X\"\n",
        "        elif col == 2:\n",
        "          symbol = \"O\"\n",
        "        print(symbol, end='')\n",
        "        print(\"|\", end='')\n",
        "      print(\"\")\n",
        "\n",
        "\n",
        "  def play(self, action):\n",
        "    player = 2\n",
        "    if self.isXTurn:\n",
        "      player = 1\n",
        "\n",
        "    self.board[action] = player\n",
        "    self.isXTurn = not self.isXTurn\n",
        "\n",
        "    winner = self.checkWin()\n",
        "    isDone = self.checkDone()\n",
        "\n",
        "    nextState = np.array(self.board, copy=True)\n",
        "    return nextState, isDone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9qxzsn0Z1wK"
      },
      "outputs": [],
      "source": [
        "game = TigTagToeGame()\n",
        "agent = Agent(isPlay=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEwLZHWBdznG",
        "outputId": "eaf49577-ea9a-4151-8f57-5c6de1be5a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|*|*|*|\n",
            "|*|*|*|\n",
            "|*|*|*|\n"
          ]
        }
      ],
      "source": [
        "game.showBoard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cqqmICZZ75c",
        "outputId": "2dd1bb48-dc3e-41a6-efc0-651519d5eba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- AI vs Human ---\n",
            "|*|*|*|\n",
            "|*|*|*|\n",
            "|*|*|*|\n",
            "thinking x [2.5486516652777658, 2.5613031642264725, 2.5486516652777658, 2.5613031642264725, 2.5233456822791234, 2.5613031642264725, 2.5486516652777658, 2.5613031642264725, 2.5486516652777658]\n",
            "4\n",
            "--- AI vs Human ---\n",
            "|*|*|*|\n",
            "|*|X|*|\n",
            "|*|*|*|\n",
            "thinking [1.9814297492040436, 1.3680741084176464, 1.9814297492040436, 1.3680741084176464, 0, 1.3680741084176464, 1.9814297492040436, 1.3680741084176464, 1.9814297492040436]\n",
            "0\n",
            "--- AI vs Human ---\n",
            "|O|*|*|\n",
            "|*|X|*|\n",
            "|*|*|*|\n",
            "thinking x [0, 2.011396460074203, 1.9347372561319678, 2.034971170476954, 0, 1.9774592720400521, 1.8578920915367867, 1.9718494659689485, 2.008680969715967]\n",
            "3\n",
            "--- AI vs Human ---\n",
            "|O|*|*|\n",
            "|X|X|*|\n",
            "|*|*|*|\n",
            "thinking [0, 1.0160304153785504, 1.1831117339411237, 0, 0, 1.4886514125203743, 1.3841095458629282, -0.23500000000000004, -1]\n",
            "5\n",
            "--- AI vs Human ---\n",
            "|O|*|*|\n",
            "|X|X|O|\n",
            "|*|*|*|\n",
            "thinking x [0, 1.4906572543472842, 1.5245092848051347, 0, 0, 0, 1.0527658171269818, 1.523418385516253, 1.5083810336863364]\n",
            "2\n",
            "--- AI vs Human ---\n",
            "|O|*|X|\n",
            "|X|X|O|\n",
            "|*|*|*|\n",
            "thinking [0, -1, 0, 0, 0, 0, 0.9949999999999999, 0.914494554035, -0.23500000000000004]\n",
            "6\n",
            "--- AI vs Human ---\n",
            "|O|*|X|\n",
            "|X|X|O|\n",
            "|O|*|*|\n",
            "thinking x [0, 0.9950139909720535, 0, 0, 0, 0, 0, 1.0114776518550936, 0.9949999999999999]\n",
            "7\n",
            "--- AI vs Human ---\n",
            "|O|*|X|\n",
            "|X|X|O|\n",
            "|O|X|*|\n",
            "thinking [0, 0.5, 0, 0, 0, 0, 0, 0, -1]\n",
            "1\n",
            "--- AI vs Human ---\n",
            "|O|O|X|\n",
            "|X|X|O|\n",
            "|O|X|*|\n",
            "thinking x [0, 0, 0, 0, 0, 0, 0, 0, 0.5]\n",
            "8\n",
            "game end\n",
            "|O|O|X|\n",
            "|X|X|O|\n",
            "|O|X|X|\n",
            "Draw!!\n"
          ]
        }
      ],
      "source": [
        "isDone = False\n",
        "game.reset()\n",
        "\n",
        "while not isDone:\n",
        "  state = game.getState()\n",
        "  print(\"--- AI vs Human ---\")\n",
        "  game.showBoard()\n",
        "\n",
        "  action = 0\n",
        "  if game.isXTurn:\n",
        "    action = agent.act(state)\n",
        "    # isInputValidate = False\n",
        "    # while not isInputValidate:\n",
        "    #   action = int(input(\"player turn (X):\"))\n",
        "    #   if len(state) > action and state[action] == 0:\n",
        "    #     isInputValidate = True\n",
        "    print(\"thinking x\", getHashValue(stateToHash(state)))\n",
        "    if state[4] == 0:\n",
        "      action = 4\n",
        "  else:\n",
        "    sstate = swapSide(state)\n",
        "    print(\"thinking\", getHashValue(stateToHash(sstate)))\n",
        "    action = agent.act(swapSide(state))\n",
        "  print(action)\n",
        "  state, isDone = game.play(action)\n",
        "\n",
        "print(\"game end\")\n",
        "game.showBoard()\n",
        "winner = game.checkWin()\n",
        "if winner == 1:\n",
        "  print(\"Congratulation the player win.\")\n",
        "elif winner == 2:\n",
        "  print(\"AI is the winner, We'll conquer the world\")\n",
        "else:\n",
        "  print(\"Draw!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6win0UDMzriH"
      },
      "source": [
        "# Validate\n",
        "## Expected that Q-learning agent will never lose!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXMxcOSrzouq",
        "outputId": "2aaa2a58-5dfb-4c54-d596-e50857b54f98"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'game' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\GitHub\\programming_python\\Machine_Learning\\สำเนาของ_q_learning_tigtagtoe.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/programming_python/Machine_Learning/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_q_learning_tigtagtoe.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/programming_python/Machine_Learning/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_q_learning_tigtagtoe.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   isDone \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/programming_python/Machine_Learning/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_q_learning_tigtagtoe.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   game\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/programming_python/Machine_Learning/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_q_learning_tigtagtoe.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39m# print(\"game No.\", i)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/programming_python/Machine_Learning/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_q_learning_tigtagtoe.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m isDone:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'game' is not defined"
          ]
        }
      ],
      "source": [
        "for i in range(1000):\n",
        "  isDone = False\n",
        "  game.reset()\n",
        "\n",
        "  # print(\"game No.\", i)\n",
        "  while not isDone:\n",
        "    state = game.getState()\n",
        "    action = 0\n",
        "    if game.isXTurn:\n",
        "      hash = stateToHash(state)\n",
        "      possibleActions = getPossibilityActions(hash)\n",
        "      idx = [i for i in range(len(possibleActions)) if possibleActions[i] == 1]\n",
        "      action = random.choice(idx)\n",
        "    else:\n",
        "      action = agent.act(swapSide(state))\n",
        "      if state[4] == 0:\n",
        "        action = 4\n",
        "    # game.showBoard()\n",
        "\n",
        "    state, isDone = game.play(action)\n",
        "  winner = game.checkWin()\n",
        "  if winner == 1:\n",
        "    print(\"What!! AI Lose a randomness ?\")\n",
        "    game.showBoard()\n",
        "    break\n",
        "  elif winner == 2:\n",
        "    # pass\n",
        "    print(\"AI is the winner, We'll conquer the world\")\n",
        "  else:\n",
        "    print(\"Draw!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53g6I_oQ5irV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "สำเนาของ q-learning-tigtagtoe.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d43a25d1af2961156a397965ce5be382d1d6f6f318f4adad90d5e74324cbd7a2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
